import azure.functions as func
import logging
import json
import os
from openai import AzureOpenAI
from azure.cosmos import CosmosClient
from datetime import datetime, timezone
import pytz
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
AZURE_OPENAI_ENDPOINT = os.environ["AZURE_OPENAI_ENDPOINT"]
AZURE_OPENAI_API_KEY = os.environ["AZURE_OPENAI_API_KEY"]
AZURE_OPENAI_DEPLOYMENT = os.environ["AZURE_OPENAI_DEPLOYMENT"]
OPENAI_API_VERSION = os.environ["OPENAI_API_VERSION"]
OPENAI_GPT_MODEL = os.environ["OPENAI_GPT_MODEL"]

COSMOS_ENDPOINT = os.environ["COSMOS_DB_ENDPOINT"]
COSMOS_KEY = os.environ["COSMOS_DB_KEY"]
COSMOS_DB = os.environ["COSMOS_DB_NAME"]
COSMOS_PARKING_CONTAINER = os.environ["COSMOS_DB_CONTAINER"]  # ì£¼ì°¨ì¥ ì»¨í…Œì´ë„ˆ
COSMOS_FACILITY_CONTAINER = os.environ["COSMOS_FACILITY_CONTAINER"] # ì‹œì„¤ ì»¨í…Œì´ë„ˆ
COSMOS_FLIGHT_CONTAINER = os.environ["COSMOS_FLIGHT_CONTAINER"]  # í•­ê³µí¸ ì»¨í…Œì´ë„ˆ

APPLICATION_JSON = "application/json"

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = AzureOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_key=AZURE_OPENAI_API_KEY,
    api_version=OPENAI_API_VERSION
)

cosmos_client = CosmosClient(COSMOS_ENDPOINT, COSMOS_KEY)
db_client = cosmos_client.get_database_client(COSMOS_DB)
parking_container = db_client.get_container_client(COSMOS_PARKING_CONTAINER)
facility_container = db_client.get_container_client(COSMOS_FACILITY_CONTAINER)
flight_container = db_client.get_container_client(COSMOS_FLIGHT_CONTAINER)

# í•­ê³µí¸ ë²ˆí˜¸ ì¶”ì¶œ í•¨ìˆ˜ ì¶”ê°€
def extract_flight_number(text):
    """í…ìŠ¤íŠ¸ì—ì„œ í•­ê³µí¸ ë²ˆí˜¸ ì¶”ì¶œ"""
    # í•­ê³µí¸ ë²ˆí˜¸ íŒ¨í„´: ì˜ë¬¸ 2-3ìë¦¬ + ìˆ«ì 3-4ìë¦¬
    flight_patterns = [
        r'\b[A-Z]{2}[0-9]{3,4}\b',  # KE123, AF5369
        r'\b[0-9][A-Z][0-9]{3,4}\b',  # 7C1301
        r'\b[A-Z][0-9][A-Z][0-9]{3,4}\b'  # íŠ¹ìˆ˜ íŒ¨í„´
    ]
    
    for pattern in flight_patterns:
        matches = re.findall(pattern, text.upper())
        if matches:
            return matches[0]
    
    return None

# í˜„ì¬ ì‹œê°„ ë° ì‹œê°„ ê´€ë ¨ í•¨ìˆ˜ë“¤
def get_current_time_info():
    """í˜„ì¬ í•œêµ­ ì‹œê°„ ì •ë³´ ë°˜í™˜"""
    kst = pytz.timezone("Asia/Seoul")
    current_datetime = datetime.now(timezone.utc).astimezone(kst)
    
    return {
        "datetime": current_datetime,
        "date": current_datetime.strftime("%Yë…„ %mì›” %dì¼"),
        "time": current_datetime.strftime("%H:%M"),
        "weekday": current_datetime.strftime("%A"),
        "weekday_ko": ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"][current_datetime.weekday()],
        "formatted": current_datetime.strftime("%Yë…„ %mì›” %dì¼ %H:%M (%A)")
    }

def parse_flight_time(flight_data):
    """í•­ê³µí¸ ì‹œê°„ ì •ë³´ë¥¼ íŒŒì‹±í•˜ì—¬ datetime ê°ì²´ë¡œ ë³€í™˜"""
    try:
        if not flight_data:
            return None
            
        # ë‚ ì§œì™€ ì‹œê°„ ì •ë³´ ì¶”ì¶œ
        date_str = str(flight_data.get('date', ''))
        scheduled_time = flight_data.get('scheduleDateTime', '')
        estimated_time = flight_data.get('estimatedDateTime', '')
        
        if not date_str or not scheduled_time:
            return None
            
        # ë‚ ì§œ íŒŒì‹± (YYYYMMDD í˜•íƒœ)
        if len(date_str) == 8:
            year = int(date_str[:4])
            month = int(date_str[4:6])
            day = int(date_str[6:8])
        else:
            return None
            
        # ì‹œê°„ íŒŒì‹± (HH:MM í˜•íƒœ)
        time_to_use = estimated_time if estimated_time else scheduled_time
        if ':' in time_to_use:
            hour, minute = map(int, time_to_use.split(':'))
        else:
            return None
            
        # í•œêµ­ ì‹œê°„ìœ¼ë¡œ datetime ê°ì²´ ìƒì„±
        kst = pytz.timezone("Asia/Seoul")
        flight_datetime = datetime(year, month, day, hour, minute, tzinfo=kst)
        
        return flight_datetime
        
    except Exception as e:
        logging.error(f"í•­ê³µí¸ ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return None

def get_flight_recommendations(current_time, flight_data):
    """í˜„ì¬ ì‹œê°„ê³¼ í•­ê³µí¸ ì‹œê°„ì„ ë¹„êµí•˜ì—¬ ì¶”ì²œì‚¬í•­ ì œê³µ"""
    try:
        recommendations = []
        
        for flight in flight_data[:3]:  # ìµœëŒ€ 3ê°œ í•­ê³µí¸ ë¶„ì„
            flight_datetime = parse_flight_time(flight)
            if not flight_datetime:
                continue
                
            # ì‹œê°„ ì°¨ì´ ê³„ì‚°
            time_diff = flight_datetime - current_time['datetime']
            hours_diff = time_diff.total_seconds() / 3600
            
            flight_info = f"{flight.get('airline', '')} {flight.get('flightid', '')} ({flight.get('airport', '')})"
            
            if hours_diff < 0:
                # ì´ë¯¸ ì¶œë°œí•œ í•­ê³µí¸
                recommendations.append(f"âš ï¸ {flight_info}ëŠ” ì´ë¯¸ ì¶œë°œí–ˆìŠµë‹ˆë‹¤.")
            elif hours_diff <= 1:
                # 1ì‹œê°„ ì´ë‚´ ì¶œë°œ
                recommendations.append(f"ğŸš¨ {flight_info}ê°€ 1ì‹œê°„ ì´ë‚´ ì¶œë°œí•©ë‹ˆë‹¤!\n   â†’ ì¦‰ì‹œ ë³´ì•ˆê²€ìƒ‰ëŒ€ë¡œ ì´ë™í•˜ì„¸ìš”.")
            elif hours_diff <= 2:
                # 2ì‹œê°„ ì´ë‚´ ì¶œë°œ
                recommendations.append(f"â° {flight_info}ê°€ 2ì‹œê°„ ì´ë‚´ ì¶œë°œí•©ë‹ˆë‹¤.\n   â†’ ì²´í¬ì¸ ì™„ë£Œ í›„ ë³´ì•ˆê²€ìƒ‰ëŒ€ í†µê³¼ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
            elif hours_diff <= 4:
                # 4ì‹œê°„ ì´ë‚´ ì¶œë°œ
                recommendations.append(f"âœ… {flight_info}ê¹Œì§€ {int(hours_diff)}ì‹œê°„ ì—¬ìœ ê°€ ìˆìŠµë‹ˆë‹¤.\n   â†’ ì‹ì‚¬, ì‡¼í•‘, ë©´ì„¸ì  ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            else:
                # 4ì‹œê°„ ì´ìƒ ì—¬ìœ 
                recommendations.append(f"ğŸ˜Š {flight_info}ê¹Œì§€ {int(hours_diff)}ì‹œê°„ ì´ìƒ ì—¬ìœ ê°€ ìˆìŠµë‹ˆë‹¤.\n   â†’ ê³µí•­ ì‹œì„¤ì„ ì¶©ë¶„íˆ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
        return recommendations
        
    except Exception as e:
        logging.error(f"í•­ê³µí¸ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return []

# ì‹œì„¤ ìƒí˜¸ëª… ì¶”ì¶œ í•¨ìˆ˜ ì¶”ê°€
def extract_facility_names(user_query):
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì‹œì„¤ ìƒí˜¸ëª… ì¶”ì¶œ"""
    try:
        # ì¼ë°˜ì ì¸ ìƒí˜¸ëª… íŒ¨í„´ë“¤
        common_brands = [
            # ë„ë„›
            "í¬ë¦¬ìŠ¤í”¼í¬ë¦¼", "í¬ë¦¬ìŠ¤í”¼ í¬ë¦¼", "í¬ë¦¬ìŠ¤í”¼í¬ë¦¼ë„ë„›", "ë˜í‚¨ë„ë„ˆì¸ ", "ë˜í‚¨", "ë¯¸ìŠ¤í„°ë„ë„›",
            # ì¹´í˜
            "ìŠ¤íƒ€ë²…ìŠ¤", "ì´ë””ì•¼", "íˆ¬ì¸í”Œë ˆì´ìŠ¤", "íˆ¬ì¸", "ì—”ì ¤ì¸ì–´ìŠ¤", "íŒŒìŠ¤ì¿ ì°Œ", "í• ë¦¬ìŠ¤",
            # íŒ¨ìŠ¤íŠ¸í‘¸ë“œ
            "ë§¥ë„ë‚ ë“œ", "ë²„ê±°í‚¹", "KFC", "ë¡¯ë°ë¦¬ì•„", "ë§˜ìŠ¤í„°ì¹˜", "ì„œë¸Œì›¨ì´",
            # í¸ì˜ì 
            "ì„¸ë¸ì¼ë ˆë¸", "GS25", "CU", "ì´ë§ˆíŠ¸24", "ë¯¸ë‹ˆìŠ¤í†±",
            # í•œì‹
            "ë°±ë°˜ì§‘", "í•œì •ì‹", "ê¹€ë°¥ì²œêµ­", "ê³ ë´‰ë¯¼ê¹€ë°¥", "ì£½ì´ì•¼ê¸°", "ë³¸ì£½",
            # ì¤‘ì‹
            "í™ì½©ë°˜ì ", "ë¶ê²½", "ì¤‘êµ­ì§‘", "ì§œì¥ë©´", "ì§¬ë½•",
            # ì¼ì‹
            "ì´ˆë°¥", "íšŒ", "ë¼ë©˜", "ìš°ë™", "ëˆê°€ìŠ¤", "ì¹´ì¸ ", "í…ë™",
            # ê¸°íƒ€
            "í”¼ìí—›", "íŒŒíŒŒì¡´ìŠ¤", "ë„ë¯¸ë…¸í”¼ì", "ë°°ìŠ¤í‚¨ë¼ë¹ˆìŠ¤", "ë² ë¼", "í•˜ê²ë‹¤ì¦ˆ",
            # ì€í–‰/í™˜ì „
            "ì‹ í•œì€í–‰", "ìš°ë¦¬ì€í–‰", "êµ­ë¯¼ì€í–‰", "í•˜ë‚˜ì€í–‰", "ê¸°ì—…ì€í–‰", "ë†í˜‘", "í™˜ì „ì†Œ",
            # ì‡¼í•‘
            "ë¡¯ë°ë©´ì„¸ì ", "ì‹ ë¼ë©´ì„¸ì ", "í˜„ëŒ€ë©´ì„¸ì ", "ì‹ ì„¸ê³„ë©´ì„¸ì ", "ë©´ì„¸ì "
        ]
        
        extracted_names = []
        query_upper = user_query.upper()
        
        # ë¸Œëœë“œëª… ë§¤ì¹­
        for brand in common_brands:
            if brand.upper() in query_upper:
                extracted_names.append(brand)
        
        # ì…ë ¥ í…ìŠ¤íŠ¸ ìì²´ë„ ìƒí˜¸ëª…ìœ¼ë¡œ ì¶”ê°€ (ê³µë°± ì œê±° ë²„ì „ë„)
        query_cleaned = user_query.strip()
        if query_cleaned:
            extracted_names.append(query_cleaned)
            # ê³µë°± ì œê±° ë²„ì „
            query_no_space = query_cleaned.replace(" ", "")
            if query_no_space != query_cleaned:
                extracted_names.append(query_no_space)
        
        # ì¤‘ë³µ ì œê±°
        unique_names = list(set(extracted_names))
        
        logging.info(f"ì¶”ì¶œëœ ìƒí˜¸ëª…ë“¤: {unique_names}")
        return unique_names
        
    except Exception as e:
        logging.error(f"ìƒí˜¸ëª… ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return [user_query.strip()]  # ì˜¤ë¥˜ì‹œ ì›ë³¸ ë°˜í™˜

# ì§ˆë¬¸ ë¶„ë¥˜ í•¨ìˆ˜ ê°œì„ 
def classify_question(user_query):
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜ - ìƒí˜¸ëª… ê²€ìƒ‰ ê°œì„ """
    # ë¨¼ì € í•­ê³µí¸ ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„
    flight_number = extract_flight_number(user_query)
    
    # ìƒí˜¸ëª… íŒ¨í„´ í™•ì¸
    facility_keywords = [
        "í¬ë¦¬ìŠ¤í”¼í¬ë¦¼", "ë˜í‚¨ë„ë„ˆì¸ ", "ìŠ¤íƒ€ë²…ìŠ¤", "ë§¥ë„ë‚ ë“œ", "ë²„ê±°í‚¹", "ì„¸ë¸ì¼ë ˆë¸",
        "ìœ„ì¹˜", "ì–´ë””", "ì°¾ì•„", "ì•Œë ¤ì¤˜", "ë§¤ì¥", "ìƒí˜¸", "ë¸Œëœë“œ", "ê°€ê²Œ"
    ]
    
    has_facility_keyword = any(keyword in user_query for keyword in facility_keywords)
    
    messages = [
        {"role": "system", "content": """
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
            
            1. "parking" - ì£¼ì°¨ì¥ ê´€ë ¨ ì§ˆë¬¸ (í˜¼ì¡ë„, ì”ì—¬ê³µê°„, ì£¼ì°¨ë¹„ ë“±)
            2. "facility" - ê³µí•­ ì‹œì„¤ ê´€ë ¨ ì§ˆë¬¸ (í™˜ì „ì†Œ, ì‹ë‹¹, ì‡¼í•‘, í¸ì˜ì‹œì„¤, íŠ¹ì • ìƒí˜¸ëª… ë“±)
            3. "flight" - í•­ê³µí¸ ê´€ë ¨ ì§ˆë¬¸ (ì¶œë°œ/ë„ì°© ì‹œê°„, ê²Œì´íŠ¸, ë‚ ì”¨, í•­ê³µì‚¬ ë“±)
            4. "general" - ì—¬í–‰ ì¤€ë¹„ë¬¼, ì¼ë°˜ì ì¸ ê³µí•­ ì´ìš© íŒ ë“±
            5. "mixed" - ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ê°€ ì„ì¸ ë³µí•© ì§ˆë¬¸
            6. "time" - í˜„ì¬ ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ ("ì§€ê¸ˆ ëª‡ì‹œ", "í˜„ì¬ ì‹œê°„" ë“±)
            
            íŠ¹ë³„ ê·œì¹™:
            - í•­ê³µí¸ ë²ˆí˜¸(KE1234, 7C1301 ë“±)ê°€ ìˆìœ¼ë©´ "flight"
            - íŠ¹ì • ìƒí˜¸ëª…(í¬ë¦¬ìŠ¤í”¼í¬ë¦¼, ìŠ¤íƒ€ë²…ìŠ¤ ë“±)ì´ ìˆìœ¼ë©´ "facility"
            - "ìœ„ì¹˜", "ì–´ë””", "ì°¾ì•„", "ì•Œë ¤ì¤˜" ë“±ê³¼ ìƒí˜¸ëª…ì´ í•¨ê»˜ ìˆìœ¼ë©´ "facility"
            - "ì§€ê¸ˆ ëª‡ì‹œ", "í˜„ì¬ ì‹œê°„" ë“±ì´ ìˆìœ¼ë©´ "time"
            
            JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
            {"category": "ë¶„ë¥˜ê²°ê³¼", "confidence": 0.95}
        """},
        {"role": "user", "content": user_query}
    ]
    
    try:
        response = openai_client.chat.completions.create(
            model=OPENAI_GPT_MODEL,
            messages=messages,
            response_format={"type": "json_object"},
            temperature=0.1
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # ì¶”ì¶œëœ í•­ê³µí¸ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if flight_number:
            result["flight_number"] = flight_number
            result["category"] = "flight"
        else:
            result["flight_number"] = None
            
        # ìƒí˜¸ëª… ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ facilityë¡œ ê°•ì œ ë¶„ë¥˜
        if has_facility_keyword and result["category"] not in ["flight", "time"]:
            result["category"] = "facility"
            result["confidence"] = 0.9
            
        logging.info(f"ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼: {result}")
        return result
        
    except Exception as e:
        logging.error(f"ì§ˆë¬¸ ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
        category = "facility" if has_facility_keyword else "general"
        return {
            "category": category, 
            "confidence": 0.5, 
            "flight_number": flight_number
        }

# ê¸°ì¡´ ì£¼ì°¨ì¥ ê´€ë ¨ í•¨ìˆ˜ë“¤
def get_entities(user_query):
    kst = pytz.timezone("Asia/Seoul")
    current_datetime = datetime.now(timezone.utc).astimezone(kst)
    base_date = current_datetime.strftime("%Y%m%d")
    current_hour = current_datetime.strftime("%H")
    
    extracted_keywords = []
    query_upper = user_query.upper()
    query_clean = user_query.replace(" ", "").upper()
    
    # í„°ë¯¸ë„ í‚¤ì›Œë“œ ë§¤ì¹­ - ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
    terminal_patterns = [
        ("T1", ["T1", "í„°ë¯¸ë„1", "1í„°ë¯¸ë„", "ì œ1í„°ë¯¸ë„", "í„°ë¯¸ë„ 1", "1 í„°ë¯¸ë„"]),
        ("T2", ["T2", "í„°ë¯¸ë„2", "2í„°ë¯¸ë„", "ì œ2í„°ë¯¸ë„", "í„°ë¯¸ë„ 2", "2 í„°ë¯¸ë„"])
    ]
    
    for terminal_code, patterns in terminal_patterns:
        for pattern in patterns:
            if pattern.upper() in query_upper or pattern.replace(" ", "").upper() in query_clean:
                extracted_keywords.append(terminal_code)
                break
    
    # ì£¼ì°¨ì¥ ìœ í˜• í‚¤ì›Œë“œ ë§¤ì¹­ - ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •
    parking_type_patterns = [
        ("ë‹¨ê¸°", ["ë‹¨ê¸°", "ë‹¨ê¸°ì£¼ì°¨", "ë‹¨ê¸°ì£¼ì°¨ì¥", "SHORT", "ë‹¨ê¸° ì£¼ì°¨"]),
        ("ì¥ê¸°", ["ì¥ê¸°", "ì¥ê¸°ì£¼ì°¨", "ì¥ê¸°ì£¼ì°¨ì¥", "LONG", "ì¥ê¸° ì£¼ì°¨"])
    ]
    
    for parking_type, patterns in parking_type_patterns:
        for pattern in patterns:
            if pattern.upper() in query_upper or pattern.replace(" ", "").upper() in query_clean:
                extracted_keywords.append(parking_type)
                break
    
    # ì¸µ ì •ë³´ í‚¤ì›Œë“œ ë§¤ì¹­ - ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
    import re
    
    # P1, P2, P3 ë“±ì˜ ì£¼ì°¨ì¥ êµ¬ì—­ ë§¤ì¹­
    parking_area_matches = re.findall(r'P([0-9]+)', query_upper)
    for match in parking_area_matches:
        extracted_keywords.append(f"P{match}")
    
    # ì§€ìƒ/ì§€í•˜ ì¸µ ì •ë³´ ë§¤ì¹­
    floor_matches = re.findall(r'ì§€ìƒ\s*([0-9]+)', user_query)
    for match in floor_matches:
        extracted_keywords.append(f"ì§€ìƒ{match}ì¸µ")
    
    floor_matches = re.findall(r'ì§€í•˜\s*([0-9]+)', user_query)
    for match in floor_matches:
        extracted_keywords.append(f"ì§€í•˜{match}ì¸µ")
    
    # ì¼ë°˜ ì¸µìˆ˜ ë§¤ì¹­
    floor_matches = re.findall(r'([0-9]+)ì¸µ', user_query)
    for match in floor_matches:
        extracted_keywords.append(f"{match}ì¸µ")
    
    # ì”ì—¬/ì—¬ìœ  ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
    availability_keywords = ["ì”ì—¬", "ë‚¨ì€", "ë¹ˆ", "ì‚¬ìš©ê°€ëŠ¥", "ì—¬ìœ ", "ê³µê°„", "ëŒ€ìˆ˜"]
    has_availability_query = any(keyword in user_query for keyword in availability_keywords)
    
    if has_availability_query:
        extracted_keywords.append("ì”ì—¬ê³µê°„")
    
    # ì¤‘ë³µ ì œê±°
    extracted_keywords = list(set(extracted_keywords))
    
    result = {
        "floor_keywords": extracted_keywords,
        "date": base_date,
        "time": current_hour,
        "has_availability_query": has_availability_query
    }
    
    logging.info(f"í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼: {result}")
    return json.dumps(result)

def query_similar_parking_data(user_query, entities, top_k=15):
    """ì£¼ì°¨ì¥ ë°ì´í„° ê²€ìƒ‰ - ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •"""
    
    # ì„ë² ë”© ìƒì„±
    embedding_res = openai_client.embeddings.create(
        input=user_query,
        model=AZURE_OPENAI_DEPLOYMENT
    )
    query_vector = embedding_res.data[0].embedding

    # ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰
    base_query = f"""
    SELECT TOP {top_k * 2}
        c.floor, c.parking_count, c.parking_total,
        c.congestion_rate, c.congestion_level, c.date, c.time,
        VectorDistance(c.embedding, @query_vector) as similarity_score
    FROM c
    WHERE IS_DEFINED(c.embedding)
    ORDER BY VectorDistance(c.embedding, @query_vector)
    """
    
    parameters = [{"name": "@query_vector", "value": query_vector}]
    
    try:
        results = list(parking_container.query_items(
            query=base_query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        logging.info(f"ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ ë° ì ìˆ˜ ê³„ì‚° - ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
        if entities and results:
            filtered_results = []
            floor_keywords = entities.get("floor_keywords", [])
            has_availability_query = entities.get("has_availability_query", False)
            
            logging.info(f"í•„í„°ë§ í‚¤ì›Œë“œ: {floor_keywords}")
            
            for result in results:
                score = 0
                floor_text = result.get("floor", "").upper()
                
                # ì‹¤ì œ ë°ì´í„° í˜•íƒœ: "T1 ì¥ê¸° P3 ì£¼ì°¨ì¥", "T2 ë‹¨ê¸° P1 ì£¼ì°¨ì¥" ë“±
                for keyword in floor_keywords:
                    keyword_upper = keyword.upper()
                    
                    # í„°ë¯¸ë„ ë§¤ì¹­
                    if keyword_upper in ["T1", "T2"]:
                        if floor_text.startswith(keyword_upper):
                            score += 10
                    
                    # ì£¼ì°¨ì¥ ìœ í˜• ë§¤ì¹­
                    elif keyword_upper in ["ë‹¨ê¸°", "ì¥ê¸°"]:
                        if keyword_upper in floor_text:
                            score += 8
                    
                    # ì£¼ì°¨ì¥ êµ¬ì—­ ë§¤ì¹­ (P1, P2, P3 ë“±)
                    elif keyword_upper.startswith("P") and keyword_upper[1:].isdigit():
                        if keyword_upper in floor_text:
                            score += 7
                    
                    # ì¸µ ì •ë³´ ë§¤ì¹­ (ì‹¤ì œ ë°ì´í„°ì— ì¸µ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°)
                    elif "ì¸µ" in keyword_upper:
                        if keyword_upper in floor_text:
                            score += 6
                    
                    # ì¼ë°˜ ë¶€ë¶„ ë§¤ì¹­
                    elif keyword_upper in floor_text:
                        score += 5
                
                # ì”ì—¬ ê³µê°„ ì§ˆë¬¸ì— ëŒ€í•œ ê°€ì¤‘ì¹˜
                if has_availability_query:
                    parking_total = result.get('parking_total', 0)
                    parking_count = result.get('parking_count', 0)
                    available_spaces = parking_total - parking_count
                    
                    if available_spaces > 0:
                        score += 3
                        # ì”ì—¬ ê³µê°„ ë¹„ìœ¨ì— ë”°ë¥¸ ì¶”ê°€ ì ìˆ˜
                        availability_ratio = available_spaces / parking_total if parking_total > 0 else 0
                        score += int(availability_ratio * 5)
                
                # ë‚ ì§œ/ì‹œê°„ ë§¤ì¹­
                try:
                    result_date = str(result.get("date", ""))
                    target_date = str(entities.get("date", ""))
                    if result_date == target_date:
                        score += 4
                except:
                    pass
                
                result["relevance_score"] = score
                filtered_results.append(result)
                
                logging.info(f"'{floor_text}' -> ì ìˆ˜: {score}")
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            filtered_results.sort(key=lambda x: (x["relevance_score"], -x["similarity_score"]), reverse=True)
            
            # ë†’ì€ ì ìˆ˜ ê²°ê³¼ ìš°ì„  ë°˜í™˜
            high_score_results = [r for r in filtered_results if r["relevance_score"] >= 8]
            if high_score_results:
                return high_score_results[:top_k]
            
            # ì¤‘ê°„ ì ìˆ˜ ê²°ê³¼ ë°˜í™˜
            medium_score_results = [r for r in filtered_results if r["relevance_score"] >= 5]
            if medium_score_results:
                return medium_score_results[:top_k]
            
            return filtered_results[:top_k]
        
        return results[:top_k]
        
    except Exception as e:
        logging.error(f"ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []
        
def direct_keyword_search(entities):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰"""
    try:
        if not entities or not entities.get("floor_keywords"):
            return []
        
        floor_keywords = entities.get("floor_keywords", [])
        
        # í‚¤ì›Œë“œë³„ë¡œ ì§ì ‘ ê²€ìƒ‰
        all_results = []
        
        for keyword in floor_keywords:
            if keyword in ["T1", "T2", "ë‹¨ê¸°ì£¼ì°¨ì¥", "ì¥ê¸°ì£¼ì°¨ì¥", "ì§€ìƒì¸µ", "ì§€í•˜ì¸µ"]:
                # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•œ ì¿¼ë¦¬
                query = """
                SELECT TOP 10
                    c.floor, c.parking_count, c.parking_total,
                    c.congestion_rate, c.congestion_level, c.date, c.time
                FROM c
                WHERE CONTAINS(UPPER(c.floor), UPPER(@keyword))
                ORDER BY c.date DESC, c.time DESC
                """
                
                parameters = [{"name": "@keyword", "value": keyword}]
                
                try:
                    results = list(parking_container.query_items(
                        query=query,
                        parameters=parameters,
                        enable_cross_partition_query=True
                    ))
                    
                    all_results.extend(results)
                    logging.info(f"í‚¤ì›Œë“œ '{keyword}' ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
                    
                except Exception as e:
                    logging.error(f"í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
                    continue
        
        # ì¤‘ë³µ ì œê±°
        unique_results = []
        seen = set()
        for result in all_results:
            key = (result.get('floor', ''), result.get('date', ''), result.get('time', ''))
            if key not in seen:
                seen.add(key)
                unique_results.append(result)
        
        logging.info(f"ì§ì ‘ í‚¤ì›Œë“œ ê²€ìƒ‰ ìµœì¢… ê²°ê³¼: {len(unique_results)}ê°œ")
        return unique_results[:10]
        
    except Exception as e:
        logging.error(f"ì§ì ‘ í‚¤ì›Œë“œ ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        return []

def fallback_search(entities):
    try:
        where_clauses = []
        parameters = []
        
        if entities and entities.get("floor_keywords"):
            floor_conditions = []
            for i, keyword in enumerate(entities["floor_keywords"]):
                param_name = f"@floor_keyword_{i}"
                floor_conditions.append(f"CONTAINS(UPPER(c.floor), UPPER({param_name}))")
                parameters.append({"name": param_name, "value": keyword})
            
            if floor_conditions:
                where_clauses.append(f"({' OR '.join(floor_conditions)})")
        
        if entities and entities.get("date"):
            where_clauses.append("c.date = @date")
            parameters.append({"name": "@date", "value": int(entities["date"])})
        
        where_sql = " AND ".join(where_clauses) if where_clauses else "1=1"
        
        query = f"""
        SELECT TOP 5
            c.floor, c.parking_count, c.parking_total,
            c.congestion_rate, c.congestion_level, c.date, c.time
        FROM c
        WHERE {where_sql}
        ORDER BY c.date DESC, c.time DESC
        """
        
        results = list(parking_container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        logging.info(f"Fallback ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        return results
        
    except Exception as e:
        logging.error(f"Fallback ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

# ì‹œì„¤ ê²€ìƒ‰ í•¨ìˆ˜ë“¤ - ëŒ€í­ ê°œì„ ëœ ë²„ì „
def search_exact_facility_name(user_query):
    """ìƒí˜¸ëª… ì •í™•í•œ ë§¤ì¹­ ê²€ìƒ‰"""
    try:
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ìƒí˜¸ëª… ì¶”ì¶œ
        facility_names = extract_facility_names(user_query)
        
        results = []
        for name in facility_names:
            # ì •í™•í•œ ë§¤ì¹­ ì¿¼ë¦¬
            exact_query = """
            SELECT TOP 10
                c.entrpskoreannm, c.trtmntprdlstkoreannm, c.lckoreannm,
                c.servicetime, c.arrordep, c.tel
            FROM c
            WHERE UPPER(c.entrpskoreannm) = UPPER(@facility_name)
            """
            
            parameters = [{"name": "@facility_name", "value": name}]
            
            exact_results = list(facility_container.query_items(
                query=exact_query,
                parameters=parameters,
                enable_cross_partition_query=True
            ))
            
            results.extend(exact_results)
        
        return results
        
    except Exception as e:
        logging.error(f"ì •í™•í•œ ìƒí˜¸ëª… ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

def search_partial_facility_name(user_query):
    """ìƒí˜¸ëª… ë¶€ë¶„ ë§¤ì¹­ ê²€ìƒ‰"""
    try:
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ìƒí˜¸ëª… ì¶”ì¶œ
        facility_names = extract_facility_names(user_query)
        
        results = []
        for name in facility_names:
            # ë¶€ë¶„ ë§¤ì¹­ ì¿¼ë¦¬ (CONTAINS ì‚¬ìš©)
            partial_query = """
            SELECT TOP 10
                c.entrpskoreannm, c.trtmntprdlstkoreannm, c.lckoreannm,
                c.servicetime, c.arrordep, c.tel
            FROM c
            WHERE CONTAINS(UPPER(c.entrpskoreannm), UPPER(@facility_name))
               OR CONTAINS(UPPER(c.trtmntprdlstkoreannm), UPPER(@facility_name))
            ORDER BY c.entrpskoreannm
            """
            
            parameters = [{"name": "@facility_name", "value": name}]
            
            partial_results = list(facility_container.query_items(
                query=partial_query,
                parameters=parameters,
                enable_cross_partition_query=True
            ))
            
            results.extend(partial_results)
        
        # ì¤‘ë³µ ì œê±°
        unique_results = []
        seen = set()
        for result in results:
            key = (result.get('entrpskoreannm', ''), result.get('lckoreannm', ''))
            if key not in seen:
                seen.add(key)
                unique_results.append(result)
        
        return unique_results
        
    except Exception as e:
        logging.error(f"ë¶€ë¶„ ìƒí˜¸ëª… ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

def search_facility_by_vector(user_query, top_k=10):
    """ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ ë°©ì‹"""
    try:
        # ì„ë² ë”© ìƒì„±
        embedding_res = openai_client.embeddings.create(
            input=user_query,
            model=AZURE_OPENAI_DEPLOYMENT
        )
        query_vector = embedding_res.data[0].embedding
        
        # ë²¡í„° ê²€ìƒ‰
        query = f"""
        SELECT TOP {top_k}
            c.entrpskoreannm, c.trtmntprdlstkoreannm, c.lckoreannm,
            c.servicetime, c.arrordep, c.tel,
            VectorDistance(c.embedding, @query_vector) as similarity_score
        FROM c
        WHERE IS_DEFINED(c.embedding)
        ORDER BY VectorDistance(c.embedding, @query_vector)
        """
        
        parameters = [{"name": "@query_vector", "value": query_vector}]
        
        results = list(facility_container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        return results
        
    except Exception as e:
        logging.error(f"ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

# ì‹œì„¤ ê´€ë ¨ í•¨ìˆ˜ë“¤ ëŒ€í­ ê°œì„  - ë©”ì¸ í•¨ìˆ˜
def query_facility_data(user_query, top_k=10):
    """ê³µí•­ ì‹œì„¤ ì •ë³´ ê²€ìƒ‰ - ìƒí˜¸ëª… ì§ì ‘ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€"""
    try:
        # 1ë‹¨ê³„: ìƒí˜¸ëª… ì§ì ‘ ê²€ìƒ‰ (ì •í™•í•œ ë§¤ì¹­)
        exact_results = search_exact_facility_name(user_query)
        if exact_results:
            logging.info(f"ìƒí˜¸ëª… ì§ì ‘ ê²€ìƒ‰ ì„±ê³µ: {len(exact_results)}ê°œ")
            return exact_results
        
        # 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ ê²€ìƒ‰
        partial_results = search_partial_facility_name(user_query)
        if partial_results:
            logging.info(f"ë¶€ë¶„ ë§¤ì¹­ ê²€ìƒ‰ ì„±ê³µ: {len(partial_results)}ê°œ")
            return partial_results
        
        # 3ë‹¨ê³„: ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰
        vector_results = search_facility_by_vector(user_query, top_k)
        if vector_results:
            logging.info(f"ë²¡í„° ê²€ìƒ‰ ì„±ê³µ: {len(vector_results)}ê°œ")
            return vector_results
        
        logging.info("ëª¨ë“  ê²€ìƒ‰ ë°©ë²• ì‹¤íŒ¨")
        return []
        
    except Exception as e:
        logging.error(f"ì‹œì„¤ ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        return []

# í•­ê³µí¸ ê´€ë ¨ í•¨ìˆ˜ë“¤ ëŒ€í­ ê°œì„ 
def query_flight_data(user_query, flight_number=None, top_k=10):
    """í•­ê³µí¸ ì •ë³´ ê²€ìƒ‰ - ê°œì„ ëœ ë²„ì „"""
    try:
        # í•­ê³µí¸ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì •í™•í•œ ë§¤ì¹­ ì‹œë„
        if flight_number:
            logging.info(f"í•­ê³µí¸ ë²ˆí˜¸ë¡œ ê²€ìƒ‰ ì‹œë„: {flight_number}")
            
            # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
            exact_query = """
            SELECT TOP 20
                c.date, c.hr, c.min, c.yoil, c.airline, c.flightid,
                c.scheduleDateTime, c.estimatedDateTime, c.airport, c.remark,
                c.gatenumber, c.temp, c.senstemp, c.himidity, c.wind
            FROM c
            WHERE UPPER(c.flightid) = UPPER(@flight_number)
            ORDER BY c.date DESC, c.hr DESC, c.min DESC
            """
            
            exact_params = [{"name": "@flight_number", "value": flight_number}]
            
            try:
                exact_results = list(flight_container.query_items(
                    query=exact_query,
                    parameters=exact_params,
                    enable_cross_partition_query=True
                ))
                
                logging.info(f"ì •í™•í•œ í•­ê³µí¸ ë§¤ì¹­ ê²°ê³¼ ìˆ˜: {len(exact_results)}")
                
                if exact_results:
                    return exact_results
                else:
                    # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
                    partial_query = """
                    SELECT TOP 20
                        c.date, c.hr, c.min, c.yoil, c.airline, c.flightid,
                        c.scheduleDateTime, c.estimatedDateTime, c.airport, c.remark,
                        c.gatenumber, c.temp, c.senstemp, c.himidity, c.wind
                    FROM c
                    WHERE CONTAINS(UPPER(c.flightid), UPPER(@flight_number))
                    ORDER BY c.date DESC, c.hr DESC, c.min DESC
                    """
                    
                    partial_results = list(flight_container.query_items(
                        query=partial_query,
                        parameters=exact_params,
                        enable_cross_partition_query=True
                    ))
                    
                    logging.info(f"ë¶€ë¶„ í•­ê³µí¸ ë§¤ì¹­ ê²°ê³¼ ìˆ˜: {len(partial_results)}")
                    
                    if partial_results:
                        return partial_results
                    
            except Exception as e:
                logging.error(f"í•­ê³µí¸ ì§ì ‘ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        # ë²¡í„° ê²€ìƒ‰ ì‹œë„
        logging.info("í•­ê³µí¸ ë²¡í„° ê²€ìƒ‰ ì‹œë„")
        
        embedding_res = openai_client.embeddings.create(
            input=user_query,
            model=AZURE_OPENAI_DEPLOYMENT
        )
        query_vector = embedding_res.data[0].embedding
        
        vector_query = f"""
        SELECT TOP {top_k}
            c.date, c.hr, c.min, c.yoil, c.airline, c.flightid,
            c.scheduleDateTime, c.estimatedDateTime, c.airport, c.remark,
            c.gatenumber, c.temp, c.senstemp, c.himidity, c.wind,
            VectorDistance(c.embedding, @query_vector) as similarity_score
        FROM c
        WHERE IS_DEFINED(c.embedding)
        ORDER BY VectorDistance(c.embedding, @query_vector)
        """
        
        vector_params = [{"name": "@query_vector", "value": query_vector}]
        
        results = list(flight_container.query_items(
            query=vector_query,
            parameters=vector_params,
            enable_cross_partition_query=True
        ))
        
        logging.info(f"í•­ê³µí¸ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        return results
        
    except Exception as e:
        logging.error(f"í•­ê³µí¸ ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        return []

# í†µí•© ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ê°œì„ 
def generate_comprehensive_response(user_query, category, flight_number=None):
    try:
        context_parts = []
        current_time = get_current_time_info()
        
        # í˜„ì¬ ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° (ì¦‰ì‹œ ë°˜í™˜)
        if category == "time":
            context_parts.append(f"ğŸ• í˜„ì¬ ì‹œê°„: {current_time['formatted']}")
            return f"í˜„ì¬ ì‹œê°„ì€ {current_time['formatted']}ì…ë‹ˆë‹¤."
        
        # ê¸°ë³¸ì ìœ¼ë¡œ í˜„ì¬ ì‹œê°„ ì •ë³´ ì¶”ê°€
        context_parts.append(f"ğŸ• í˜„ì¬ ì‹œê°„: {current_time['formatted']}")
        
        # ì£¼ì°¨ì¥ ì •ë³´ ì²˜ë¦¬
        if category in ["parking", "mixed"]:
            entities_str = get_entities(user_query)
            try:
                entities = json.loads(entities_str)
            except:
                entities = {}
            
            logging.info(f"ì£¼ì°¨ì¥ ê²€ìƒ‰ ì—”í‹°í‹°: {entities}")
            
            # ì£¼ì°¨ì¥ ë°ì´í„° ê²€ìƒ‰
            parking_data = query_similar_parking_data(user_query, entities, top_k=10)
            
            if parking_data:
                context_parts.append("ğŸš— ì£¼ì°¨ì¥ í˜„í™© (ì‹¤ì‹œê°„ ë°ì´í„°):")
                
                # ì”ì—¬ ê³µê°„ ì§ˆë¬¸ì¸ì§€ í™•ì¸
                has_availability_query = entities.get("has_availability_query", False)
                availability_keywords = ["ì”ì—¬", "ë‚¨ì€", "ë¹ˆ", "ì‚¬ìš©ê°€ëŠ¥", "ì—¬ìœ ", "ê³µê°„", "ëŒ€ìˆ˜"]
                is_availability_question = has_availability_query or any(keyword in user_query for keyword in availability_keywords)
                
                # êµ¬ì²´ì ì¸ ì£¼ì°¨ì¥ ê²€ìƒ‰ì¸ì§€ í™•ì¸ (ì˜ˆ: T2 ë‹¨ê¸°ì£¼ì°¨ì¥ ì§€ìƒ 1ì¸µ)
                floor_keywords = entities.get("floor_keywords", [])
                is_specific_parking_query = len(floor_keywords) >= 2  # í„°ë¯¸ë„ + ì£¼ì°¨ì¥ ìœ í˜• ë“±
                
                # ê²°ê³¼ í‘œì‹œ ë¡œì§ ê°œì„ 
                displayed_results = []
                
                # ë†’ì€ ì ìˆ˜ ê²°ê³¼ ìš°ì„  ì²˜ë¦¬
                high_score_results = [r for r in parking_data if r.get("relevance_score", 0) >= 8]
                medium_score_results = [r for r in parking_data if r.get("relevance_score", 0) >= 5 and r.get("relevance_score", 0) < 8]
                
                # êµ¬ì²´ì ì¸ ì§ˆë¬¸ì¸ ê²½ìš° ì •í™•í•œ ë§¤ì¹­ ê²°ê³¼ë§Œ í‘œì‹œ
                if is_specific_parking_query and high_score_results:
                    displayed_results = high_score_results[:3]
                    logging.info(f"êµ¬ì²´ì  ì§ˆë¬¸ - ê³ ì ìˆ˜ ê²°ê³¼ {len(displayed_results)}ê°œ í‘œì‹œ")
                elif medium_score_results:
                    displayed_results = medium_score_results[:5]
                    logging.info(f"ì¼ë°˜ ì§ˆë¬¸ - ì¤‘ê°„ì ìˆ˜ ê²°ê³¼ {len(displayed_results)}ê°œ í‘œì‹œ")
                else:
                    displayed_results = parking_data[:5]
                    logging.info(f"ê¸°ë³¸ - ëª¨ë“  ê²°ê³¼ {len(displayed_results)}ê°œ í‘œì‹œ")
                
                # ë§¤ì¹­ëœ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
                if not displayed_results:
                    context_parts.append("ğŸš— í•´ë‹¹ ì¡°ê±´ì˜ ì£¼ì°¨ì¥ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    context_parts.append(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {floor_keywords}")
                    
                    # ëŒ€ì•ˆ ì œì‹œ
                    if "T2" in floor_keywords:
                        context_parts.append("ğŸ’¡ T2 í„°ë¯¸ë„ì˜ ë‹¤ë¥¸ ì£¼ì°¨ì¥ì„ ì°¾ì•„ë³´ì‹œê² ìŠµë‹ˆê¹Œ?")
                    elif "T1" in floor_keywords:
                        context_parts.append("ğŸ’¡ T1 í„°ë¯¸ë„ì˜ ë‹¤ë¥¸ ì£¼ì°¨ì¥ì„ ì°¾ì•„ë³´ì‹œê² ìŠµë‹ˆê¹Œ?")
                else:
                    # ê²°ê³¼ í‘œì‹œ
                    for i, item in enumerate(displayed_results, 1):
                        try:
                            parking_total = item.get('parking_total', 0)
                            parking_count = item.get('parking_count', 0)
                            available = parking_total - parking_count
                            usage_rate = (parking_count / parking_total * 100) if parking_total > 0 else 0
                            
                            floor_name = item.get('floor', 'ì•Œ ìˆ˜ ì—†ìŒ')
                            congestion_level = item.get('congestion_level', 'ì•Œ ìˆ˜ ì—†ìŒ')
                            congestion_rate = item.get('congestion_rate', 0)
                            
                            # ë””ë²„ê¹… ì •ë³´ ë¡œê¹…
                            logging.info(f"ì£¼ì°¨ì¥ {i}: {floor_name}, ì „ì²´:{parking_total}, ì‚¬ìš©:{parking_count}, ì”ì—¬:{available}")
                            
                            # ì”ì—¬ ê³µê°„ ì§ˆë¬¸ì¸ ê²½ìš° ë” ìƒì„¸í•œ ì •ë³´ ì œê³µ
                            if is_availability_question:
                                context_parts.append(
                                    f"{i}. ğŸ“ {floor_name}\n"
                                    f"   â€¢ ì”ì—¬ ê³µê°„: {available}ëŒ€ (ì „ì²´ {parking_total}ëŒ€ ì¤‘)\n"
                                    f"   â€¢ ì‚¬ìš©ë¥ : {usage_rate:.1f}%\n"
                                    f"   â€¢ í˜¼ì¡ë„: {congestion_level} ({congestion_rate}%)\n"
                                    f"   â€¢ ì—…ë°ì´íŠ¸: {item.get('date', '')}-{item.get('time', '')}"
                                )
                            else:
                                context_parts.append(
                                    f"{i}. {floor_name} - "
                                    f"í˜¼ì¡ë„: {congestion_level}({congestion_rate}%), "
                                    f"ì”ì—¬: {available}ëŒ€/{parking_total}ëŒ€"
                                )
                            
                            # êµ¬ì²´ì ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ ì œê³µ
                            if is_specific_parking_query and i == 1:
                                if available > 0:
                                    context_parts.append(f"âœ… í˜„ì¬ {available}ëŒ€ì˜ ì£¼ì°¨ ê³µê°„ì´ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                                else:
                                    context_parts.append(f"âŒ í˜„ì¬ ì£¼ì°¨ ê³µê°„ì´ ê°€ë“ ì°¼ìŠµë‹ˆë‹¤.")
                                    
                        except Exception as e:
                            logging.error(f"ì£¼ì°¨ì¥ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                            context_parts.append(f"{i}. ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {item.get('floor', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                            continue
                    
                    # ìš”ì•½ ì •ë³´ ì¶”ê°€
                    if is_availability_question and displayed_results:
                        try:
                            total_available = sum(
                                (item.get('parking_total', 0) - item.get('parking_count', 0)) 
                                for item in displayed_results
                            )
                            context_parts.append(f"\nğŸ’¡ ê²€ìƒ‰ëœ ì£¼ì°¨ì¥ ì´ ì”ì—¬ ê³µê°„: {total_available}ëŒ€")
                        except Exception as e:
                            logging.error(f"ìš”ì•½ ì •ë³´ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
                    
                    # ì¶”ê°€ ì •ë³´ ì œê³µ
                    if is_specific_parking_query and displayed_results:
                        context_parts.append(f"\nğŸ“Š ê´€ë ¨ë„ ì ìˆ˜: {displayed_results[0].get('relevance_score', 0)}ì ")
                        
            else:
                context_parts.append("ğŸš— í•´ë‹¹ ì¡°ê±´ì˜ ì£¼ì°¨ì¥ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                context_parts.append(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {entities.get('floor_keywords', [])}")
                
                # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ì œì‹œ
                if entities.get('floor_keywords'):
                    context_parts.append("ğŸ’¡ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜, ì „ì²´ ì£¼ì°¨ì¥ í˜„í™©ì„ ë¬¸ì˜í•´ë³´ì„¸ìš”.")
        
        # ì‹œì„¤ ì •ë³´ ì²˜ë¦¬ - ë” ë§ì€ ê²°ê³¼ í‘œì‹œ
        if category in ["facility", "mixed", "general"]:
            facility_data = query_facility_data(user_query, top_k=15)
            if facility_data:
                context_parts.append("ğŸ¢ ê³µí•­ ì‹œì„¤ ì •ë³´:")
                # ìµœëŒ€ 8ê°œê¹Œì§€ í‘œì‹œ (ê¸°ì¡´ 3ê°œì—ì„œ ì¦ê°€)
                for i, item in enumerate(facility_data[:8], 1):
                    location = item.get('lckoreannm', '')
                    service_time = item.get('servicetime', '')
                    tel = item.get('tel', '')
                    arrordep = item.get('arrordep', '')
                    
                    context_parts.append(
                        f"{i}. {item.get('entrpskoreannm', '')}\n"
                        f"   â€¢ ì„œë¹„ìŠ¤: {item.get('trtmntprdlstkoreannm', '')}\n"
                        f"   â€¢ ìœ„ì¹˜: {location}\n"
                        f"   â€¢ êµ¬ë¶„: {arrordep}\n"
                        f"   â€¢ ìš´ì˜ì‹œê°„: {service_time}\n"
                        f"   â€¢ ì—°ë½ì²˜: {tel}"
                    )
        
        # í•­ê³µí¸ ì •ë³´ ì²˜ë¦¬
        flight_data = None
        if category in ["flight", "mixed"] or flight_number:
            flight_data = query_flight_data(user_query, flight_number)
            if flight_data:
                context_parts.append("âœˆï¸ í•­ê³µí¸ ì •ë³´:")
                for i, item in enumerate(flight_data[:5], 1):
                    weather_info = ""
                    if item.get('temp'):
                        weather_info = f"ë‚ ì”¨: {item['temp']}Â°C (ì²´ê° {item.get('senstemp', 'N/A')}Â°C), ìŠµë„: {item.get('himidity', 'N/A')}%"
                    
                    context_parts.append(
                        f"{i}. {item.get('airline', '')} {item.get('flightid', '')}\n"
                        f"   â€¢ ëª©ì ì§€: {item.get('airport', '')}\n"
                        f"   â€¢ ë‚ ì§œ: {item.get('date', '')} ({item.get('yoil', '')})\n"
                        f"   â€¢ ì˜ˆì •ì‹œê°„: {item.get('scheduleDateTime', '')}\n"
                        f"   â€¢ ì˜ˆìƒì‹œê°„: {item.get('estimatedDateTime', '')}\n"
                        f"   â€¢ ê²Œì´íŠ¸: {item.get('gatenumber', '')}\n"
                        f"   â€¢ êµ¬ë¶„: {item.get('remark', '')}\n"
                        f"   â€¢ {weather_info}"
                    )
                
                # í•­ê³µí¸ ì‹œê°„ ê¸°ë°˜ ì¶”ì²œì‚¬í•­ ìƒì„±
                recommendations = get_flight_recommendations(current_time, flight_data)
                if recommendations:
                    context_parts.append("\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
                    for rec in recommendations:
                        context_parts.append(f"   {rec}")
            else:
                context_parts.append("âœˆï¸ í•­ê³µí¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if flight_number:
                    context_parts.append(f"ê²€ìƒ‰í•œ í•­ê³µí¸ ë²ˆí˜¸: {flight_number}")
        
        # ìµœì¢… ì‘ë‹µ ìƒì„±
        if not context_parts or len(context_parts) <= 1:  # í˜„ì¬ ì‹œê°„ ì •ë³´ë§Œ ìˆëŠ” ê²½ìš°
            context_parts.append("ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            context_parts.append("ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ë³´ì‹œê±°ë‚˜, ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.")
        
        # ì»¨í…ìŠ¤íŠ¸ ì¡°í•©
        context = "\n".join(context_parts)
        
        # ì£¼ì°¨ì¥ ì§ˆë¬¸ì— ëŒ€í•œ íŠ¹ë³„ ì²˜ë¦¬
        parking_keywords = ['ì”ì—¬', 'ë‚¨ì€', 'ë¹ˆ', 'ì‚¬ìš© ê°€ëŠ¥', 'ì£¼ì°¨ ê°€ëŠ¥', 'ì—¬ìœ ', 'ê³µê°„']
        is_parking_availability_question = any(keyword in user_query for keyword in parking_keywords)
        
        # GPT ì‘ë‹µ ìƒì„±
        system_prompt = """
        ë‹¹ì‹ ì€ ì¸ì²œêµ­ì œê³µí•­ì˜ ì¢…í•© ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
        
        ì¤‘ìš”í•œ ì§€ì¹¨:
        1. ì£¼ì°¨ì¥ ì •ë³´ëŠ” ì‹¤ì‹œê°„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ ì •í™•í•œ ì •ë³´ì…ë‹ˆë‹¤.
        2. ì£¼ì°¨ì¥ ì”ì—¬ ê³µê°„ ì§ˆë¬¸ì—ëŠ” ë°˜ë“œì‹œ ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ìˆ«ìë¥¼ ì œê³µí•˜ì„¸ìš”.
        3. "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ëŠ” ë‹µë³€ì€ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        4. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ì£¼ì°¨ì¥ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í™œìš©í•˜ì„¸ìš”.
        5. ì˜ì–´ë¡œ ì§ˆë¬¸ì„ ë°›ì•˜ì„ ê²½ìš°, ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
        
        ì—­í• :
        1. í˜„ì¬ ì‹œê°„ ê¸°ì¤€ ì •ë³´ ì œê³µ (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        2. ì£¼ì°¨ì¥ ì •ë³´ (í˜¼ì¡ë„, ì”ì—¬ê³µê°„ ë“±) ì•ˆë‚´
        3. ê³µí•­ ì‹œì„¤ (í™˜ì „ì†Œ, ì‹ë‹¹, í¸ì˜ì‹œì„¤ ë“±) ì•ˆë‚´ - ê°€ëŠ¥í•œ ë§ì€ ì˜µì…˜ ì œê³µ
        4. í•­ê³µí¸ ì •ë³´ (ì¶œë°œ/ë„ì°© ì‹œê°„, ê²Œì´íŠ¸, ë‚ ì”¨ ë“±) ì•ˆë‚´
        5. í•­ê³µí¸ ì‹œê°„ ê¸°ë°˜ ë§ì¶¤í˜• ì¶”ì²œì‚¬í•­ ì œê³µ
        6. ì—¬í–‰ ì¤€ë¹„ë¬¼ ë° ê³µí•­ ì´ìš© íŒ ì œê³µ
        
        ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
        - ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€
        - êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
        - ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
        - ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ë‹µë³€
        - ì‹œì„¤ ì •ë³´ ìš”ì²­ì‹œ ê°€ëŠ¥í•œ ë§ì€ ì˜µì…˜ (ìµœì†Œ 3ê°œ ì´ìƒ 5ê°œ ì´í•˜)ë¥¼ ì œê³µí•˜ì—¬ ì„ íƒì˜ í­ì„ ë„“í˜€ì£¼ì„¸ìš”
        - í•­ê³µí¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ëª…í™•íˆ ì•ˆë‚´í•´ì£¼ì„¸ìš”
        - í˜„ì¬ ì‹œê°„ê³¼ í•­ê³µí¸ ì‹œê°„ì„ ë¹„êµí•˜ì—¬ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
        - ì¶”ê°€ì ì¸ íŒì´ë‚˜ ì£¼ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ í•¨ê»˜ ì œê³µ
        - ì§ˆë¬¸ì´ ê³µí•­ ë° í•­ê³µí¸ê³¼ ê±°ë¦¬ê°€ ë¨¼ ê²½ìš°, ì •ì¤‘í•˜ê²Œ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸ì˜ ë‹µë³€ì€ í•  ìˆ˜ ì—†ë‹¤ê³  ë‹µë³€í•˜ì„¸ìš”.
        - ì •ë³´ê°€ ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ í™•ì¸í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
        - ì‹¤ì‹œê°„ ì •ë³´(í•­ê³µí¸, ì£¼ì°¨ì¥, í™˜ì „ì†Œ ìš´ì˜ ë“±)ëŠ” ë°˜ë“œì‹œ ìµœì‹  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. ì‹¤ì‹œê°„ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì´ë¥¼ ëª…í™•íˆ ê³ ì§€í•˜ì„¸ìš”.
        - ì§ˆë¬¸ì„ ì™¸êµ­ì–´ë¡œ ë°›ì•˜ì„ ê²½ìš°, ì™¸êµ­ì¸ì¼ ê²½ìš°ê°€ ë†’ìœ¼ë‹ˆ í•´ë‹¹ ì–¸ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
        
        ì£¼ì°¨ì¥ ì •ë³´ íŠ¹ë³„ ì§€ì¹¨:
        - ì£¼ì°¨ì¥ ë°ì´í„°ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ì •í™•í•œ ì •ë³´ì…ë‹ˆë‹¤.
        - ì”ì—¬ ê³µê°„, ì”ì—¬ ëŒ€ìˆ˜ ì§ˆë¬¸ì—ëŠ” ì œê³µëœ ìˆ«ìë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.
        - "ì‹¤ì‹œê°„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤" ê°™ì€ ë‹µë³€ì€ í•˜ì§€ ë§ˆì„¸ìš”.
        - ì£¼ì°¨ì¥ ê´€ë ¨ ì§ˆë¬¸: {is_parking_availability_question}
        
        íŠ¹ë³„ ì§€ì¹¨:
        - í˜„ì¬ ì‹œê°„ ì§ˆë¬¸ì—ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
        - í•­ê³µí¸ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ì‹œê°„ ë¹„êµë¥¼ í†µí•œ ë§ì¶¤í˜• ì¶”ì²œì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
        - ê¸´ê¸‰ìƒí™©(1-2ì‹œê°„ ì´ë‚´ ì¶œë°œ)ì—ëŠ” ëª…í™•í•œ í–‰ë™ ì§€ì¹¨ì„ ì œê³µí•˜ì„¸ìš”
        - ì ˆëŒ€ ì •í™•í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì œê³µí•˜ì§€ ë§ˆì„¸ìš”
        - ë‹¤ë¥¸ ì–¸ì–´ë¡œ ì§ˆë¬¸ì„ ë°›ì•˜ì„ ê²½ìš° í•´ë‹¹ ì–¸ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
        - ì˜ì–´ë¡œ ì§ˆë¬¸ì„ ë°›ì•˜ì„ ê²½ìš°, ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
        """
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"ì§ˆë¬¸: {user_query}\n\nê´€ë ¨ ì •ë³´:\n{context}"}
        ]
        
        response = openai_client.chat.completions.create(
            model=OPENAI_GPT_MODEL,
            messages=messages,
            temperature=0.2,
            max_tokens=1500  # í† í° ìˆ˜ ì¦ê°€
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        logging.error(f"í†µí•© ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ê¸°ì¡´ ì£¼ì°¨ì¥ ì „ìš© í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
def generate_parking_response(user_query):
    """ì£¼ì°¨ì¥ ì „ìš© ì‘ë‹µ ìƒì„± (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
    return generate_comprehensive_response(user_query, "parking")

# Static Web Appìš© ë©”ì¸ í•¨ìˆ˜
async def main(req: func.HttpRequest) -> func.HttpResponse:
    """Static Web Appì—ì„œ í˜¸ì¶œë˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    
    # CORS í—¤ë” ì„¤ì •
    headers = {
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type, Authorization"
    }
    
    try:
        # OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS preflight)
        if req.method == "OPTIONS":
            return func.HttpResponse(
                "",
                headers=headers,
                status_code=200
            )
        
        # POST ìš”ì²­ë§Œ ì²˜ë¦¬
        if req.method != "POST":
            return func.HttpResponse(
                json.dumps({"status": "error", "message": "POST ìš”ì²­ë§Œ ì§€ì›ë©ë‹ˆë‹¤"}),
                mimetype=APPLICATION_JSON,
                headers=headers,
                status_code=405
            )
        
        # ìš”ì²­ ë³¸ë¬¸ íŒŒì‹±
        body = req.get_json()
        if not body or "question" not in body:
            return func.HttpResponse(
                json.dumps({"status": "error", "message": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"}),
                mimetype=APPLICATION_JSON,
                headers=headers,
                status_code=400
            )
        
        question = body.get("question", "").strip()
        if not question:
            return func.HttpResponse(
                json.dumps({"status": "error", "message": "ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}),
                mimetype=APPLICATION_JSON,
                headers=headers,
                status_code=400
            )
        
        logging.info(f"ì§ˆë¬¸ ìˆ˜ì‹ : {question}")
        
        # ì§ˆë¬¸ ë¶„ë¥˜
        classification = classify_question(question)
        category = classification.get("category", "general")
        flight_number = classification.get("flight_number")
        
        logging.info(f"ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬: {category}, í•­ê³µí¸ ë²ˆí˜¸: {flight_number}")
        
        # í†µí•© ì‘ë‹µ ìƒì„±
        answer = generate_comprehensive_response(question, category, flight_number)
        
        return func.HttpResponse(
            json.dumps({
                "status": "success", 
                "answer": answer,
                "category": category,
                "flight_number": flight_number,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }, ensure_ascii=False),
            mimetype=APPLICATION_JSON,
            headers=headers,
            status_code=200
        )

    except Exception as e:
        logging.error(f"ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return func.HttpResponse(
            json.dumps({
                "status": "error", 
                "message": "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                "error_detail": str(e)
            }),
            mimetype=APPLICATION_JSON,
            headers=headers,
            status_code=500
        )
